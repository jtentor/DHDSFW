{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_train_read() :\n",
    "    u''' Reads and prepare data from blog feedback data train set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    header = pd.read_csv(\"./data/blogData_label.csv\", header=None)\n",
    "    header = list(header[0])\n",
    "    \n",
    "    if len(header) != data.shape[1] :\n",
    "        raise Exception('Los encabezados y la cantidad de características NO COINCIDE !!!')\n",
    "\n",
    "    data.columns = header\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 281)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = blogData_train_read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_labels(data) :\n",
    "    u''' Create a dictionary with some keys associates to list of features in the final work dataframe\n",
    "    \n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    labels['sd_nc_total_before_BT'] = columns[0:5]\n",
    "    labels['sd_nc_24_before_BT'] = columns[5:10]\n",
    "    labels['sd_nc_between_24_48'] = columns[10:15]\n",
    "    labels['sd_nc_first_24_BT'] = columns[15:20]\n",
    "    labels['sd_nc_diff_24_48'] = columns[20:25]\n",
    "    \n",
    "    labels['sd_nl_total_before_BT'] = columns[25:30]\n",
    "    labels['sd_nl_24_before_BT'] = columns[30:35]\n",
    "    labels['sd_nl_between_24_48'] = columns[35:40]\n",
    "    labels['sd_nl_first_24_BT'] = columns[40:45]\n",
    "    labels['sd_nl_diff_24_48'] = columns[45:50]\n",
    "    \n",
    "    labels['nc_total_before_BT'] = columns[50:51]\n",
    "    labels['nc_24_before_BT'] = columns[51:52]\n",
    "    labels['nc_between_24_48'] = columns[52:53]\n",
    "    labels['nc_first_24_BT'] = columns[53:54]\n",
    "    labels['nc_diff_24_48'] = columns[54:55]\n",
    "    \n",
    "    labels['nl_total_before_BT'] = columns[55:56]\n",
    "    labels['nl_24_before_BT'] = columns[56:57]\n",
    "    labels['nl_between_24_48'] = columns[57:58]\n",
    "    labels['nl_first_24_BT'] = columns[58:59]\n",
    "    labels['nl_diff_24_48'] = columns[59:60]\n",
    "    \n",
    "    labels['nc'] = columns[50:55]\n",
    "    labels['nl'] = columns[55:60]\n",
    "\n",
    "    labels['timelength_post_BT'] = columns[60:61]\n",
    "    labels['length_post'] = columns[61:62]\n",
    "    \n",
    "    labels['tl_post'] = columns[60:62]\n",
    "\n",
    "    labels['frequent_word'] = columns[62:262]\n",
    "\n",
    "    labels['weekday_BT'] = columns[262:269]\n",
    "    labels['weekday_post'] = columns[269:276]\n",
    "    \n",
    "    labels['parents'] = columns[276:280]\n",
    "    labels['comments'] = columns[280:281]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = blogData_labels(data)\n",
    "target = 'comments'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = lambda v: round(v, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Regression_Models\"></a>\n",
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RM_Estimator :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name, estimator, gs_param_grid=None) :\n",
    "        # self.alias = alias\n",
    "        self.name = name\n",
    "        self.estimator = estimator\n",
    "        self.gs_param_grid = gs_param_grid\n",
    "        self.gs_estimator = None\n",
    "        \n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_evaluate(rm_result, rm_models, X_train, y_train) :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    for rm in rm_models :\n",
    "\n",
    "        scoring = 'neg_root_mean_squared_error'\n",
    "        cv = StratifiedKFold(n_splits=2, random_state=11, shuffle=True)\n",
    "        \n",
    "        gs = GridSearchCV(\n",
    "            estimator=rm.estimator, # scikit-learn estimator interface\n",
    "            param_grid=rm.gs_param_grid, # dictionart key=parametrer, value=list of paraameter posible values\n",
    "            scoring=scoring, # strategy to evaluate performance of cross-validated\n",
    "            n_jobs=-2, # jobs in parallel -2 : all processors minus one\n",
    "            refit=True, # refit estimator using best parameters\n",
    "            cv=cv, # cross-validated splitting strategy\n",
    "            return_train_score=False, # include training scores\n",
    "            verbose=1 # display fold parameters, score, time, ...\n",
    "        )\n",
    "        \n",
    "        print('Gridsearch para', rm.name, '...')\n",
    "\n",
    "        gs.fit(X_train, y_train)\n",
    "        rm.gs_estimator = gs.best_estimator_\n",
    "        \n",
    "        y_pred = gs.predict(X_train)\n",
    "        gs_rmse = ROUND(np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "        \n",
    "        rm_result = rm_result.append(\n",
    "            pd.Series(\n",
    "                data=[rm.name, \n",
    "                      gs.best_params_, \n",
    "                      gs.best_score_, \n",
    "                      gs_rmse\n",
    "                     ], \n",
    "                index=rm_result.columns\n",
    "                ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    return rm_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rm_models = []\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Linear Regression',\n",
    "#         estimator=LinearRegression(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Ridge',\n",
    "#         estimator=Ridge(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Lasso',\n",
    "#         estimator=Lasso(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Elastic Net',\n",
    "#         estimator=ElasticNet(),\n",
    "#         gs_param_grid={\n",
    "#             'alpha' : [1.0], \n",
    "#             'l1_ratio' : [0, 0.5, 1] # 0 : no L2 penalty (Ridge);  1 : no L1 penalty (Lasso)\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='K-Nearest Neighbors',\n",
    "#         estimator=KNeighborsRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'n_jobs' : [-2], \n",
    "#             'n_neighbors' : [5, 10], \n",
    "#             'p' : [2], # euclidian_distance\n",
    "#             'weights' : ['uniform'] # equally weighted\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "rm_models.append(\n",
    "    RM_Estimator(\n",
    "        name='Random Forest Regressor',\n",
    "        estimator=RandomForestRegressor(),\n",
    "        gs_param_grid={\n",
    "            'max_depth' : [3], \n",
    "            'n_estimators' : [500], \n",
    "            'n_jobs' : [-2], \n",
    "            'random_state' : [127]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Gradient Boosting Regressor',\n",
    "#         estimator=GradientBoostingRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'learning_rate' : [0.1, 0.2], \n",
    "#             'max_depth' : [3], \n",
    "#             'n_estimators' : [500], \n",
    "#             'random_state' : [127], \n",
    "#             'verbose' : [0]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='XGBoost (default)',\n",
    "#         estimator=xgb.XGBRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'gamma' : [0], # (min_split_loss) minimum loss reduction\n",
    "#             'learning_rate' : [0.3], # (eta) step size shrinkage\n",
    "#             'max_depth' : [6], # maximum depth of tree\n",
    "#             'n_estimators' : [500], \n",
    "#             'n_jobs' : [-2], # jobs in parallel -2 : all processors minus one\n",
    "#             'random_state' : [127], \n",
    "#             'reg_alpha' : [0], # (alpha) L1 regularization\n",
    "#             'reg_lambda' : [1] # (lambda) L2 regularization\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "rm_models.append(\n",
    "    RM_Estimator(\n",
    "        name='XGBoost L1 y L2',\n",
    "        estimator=xgb.XGBRegressor(),\n",
    "        gs_param_grid={\n",
    "            'gamma' : [1], \n",
    "            'learning_rate' : [0.2], \n",
    "            'max_depth' : [12], \n",
    "            'n_estimators' : [1000], \n",
    "            'n_jobs' : [-2], # jobs in parallel -2 : all processors minus one\n",
    "            'random_state' : [127], \n",
    "            'reg_alpha' : [1000], # L1 regularization\n",
    "            'reg_lambda' : [1000] # L2 regularization\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data.drop(columns=[target])\n",
    "y_train = data[target].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=scaler.transform(X_train), \n",
    "    columns=list(X_train.columns)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Random Forest Regressor ...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Gridsearch para XGBoost L1 y L2 ...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "source": [
    "# ignore code\n",
    "if True :\n",
    "    rm_columns = ['model', 'params', 'cv_score', 'RMSE']\n",
    "    rm_result = pd.DataFrame(columns=rm_columns)\n",
    "\n",
    "    rm_result = rm_evaluate(rm_result, rm_models, X_train, y_train)\n",
    "\n",
    "    pd.options.display.max_colwidth = 500 \n",
    "    rm_result.sort_values(by=['RMSE'], axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500, 'n_jobs': -2, 'random_state': 127}</td>\n",
       "      <td>-26.519411</td>\n",
       "      <td>25.5614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost L1 y L2</td>\n",
       "      <td>{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000}</td>\n",
       "      <td>-25.481842</td>\n",
       "      <td>14.9075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  \\\n",
       "0  Random Forest Regressor   \n",
       "1          XGBoost L1 y L2   \n",
       "\n",
       "                                                                                                                                                params  \\\n",
       "0                                                                             {'max_depth': 3, 'n_estimators': 500, 'n_jobs': -2, 'random_state': 127}   \n",
       "1  {'gamma': 1, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000}   \n",
       "\n",
       "    cv_score     RMSE  \n",
       "0 -26.519411  25.5614  \n",
       "1 -25.481842  14.9075  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 3, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'n_jobs': -2, 'oob_score': False, 'random_state': 127, 'verbose': 0, 'warm_start': False}\n",
      "XGBoost L1 y L2 {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 1, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.2, 'max_delta_step': 0, 'max_depth': 12, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 1000, 'n_jobs': -2, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "for rm in rm_models :\n",
    "    print(rm.name, rm.gs_estimator.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.XGBRegressor()\n",
    "\n",
    "# model_params = {\n",
    "#     'gamma': 1, \n",
    "#     'learning_rate': 0.2, \n",
    "#     'max_depth': 12, \n",
    "#     'n_estimators': 1000, \n",
    "#     'n_jobs': -2, \n",
    "#     'random_state': 127, \n",
    "#     'reg_alpha': 1000, \n",
    "#     'reg_lambda': 1000\n",
    "# }\n",
    "\n",
    "# model.set_params(**model_params)\n",
    "\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279']\n"
     ]
    }
   ],
   "source": [
    "data_columns = [str(c) for c in range(rm_models[0].gs_estimator.n_features_in_) ]\n",
    "\n",
    "print(data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "XGBoost L1 y L2\n"
     ]
    }
   ],
   "source": [
    "for rm in rm_models :\n",
    "    print(rm.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_feature_importance(rm_models, data_columns) :\n",
    "    u'''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = pd.DataFrame(columns=['model'] + list(data_columns))\n",
    "    \n",
    "    for rm in rm_models :\n",
    "        result = result.append(\n",
    "            pd.Series(\n",
    "                data=[rm.name] + list(rm.gs_estimator.feature_importances_), \n",
    "                index=result.columns\n",
    "            ), \n",
    "            ignore_index=True \n",
    "        )\n",
    "\n",
    "    result = pd.DataFrame(result.mean(), columns=['rate'])\n",
    "    result.reset_index(drop=False, inplace=True)\n",
    "    result.rename(columns={'index' : 'feature'}, inplace=True)\n",
    "    result.sort_values(by='rate', ascending=False, inplace=True)\n",
    "    \n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "    result['rank'] = result.index\n",
    "    \n",
    "    # result.reset_index(drop=False, inplace=True)\n",
    "    # result.rename(columns={'index' : 'feature_index'}, inplace=True)\n",
    "    # result = result[['feature', 'feature_index', 'importance']]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_alias = {\n",
    "    'Random Forest Regressor' : 'RFR', \n",
    "    'XGBoost L1 y L2' : 'XGB', \n",
    "    'Z' : 'Z'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rate</th>\n",
       "      <th>rank</th>\n",
       "      <th>rate Random Forest Regressor</th>\n",
       "      <th>rank Random Forest Regressor</th>\n",
       "      <th>rate XGBoost L1 y L2</th>\n",
       "      <th>rank XGBoost L1 y L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timelength_post_BT</td>\n",
       "      <td>0.177859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_nc_diff_24_48</td>\n",
       "      <td>0.096395</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039033</td>\n",
       "      <td>7</td>\n",
       "      <td>0.153757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nc_24_before_BT</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>2</td>\n",
       "      <td>0.159542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std_nc_24_before_BT</td>\n",
       "      <td>0.083842</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044640</td>\n",
       "      <td>6</td>\n",
       "      <td>0.123043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median_nc_24_before_BT</td>\n",
       "      <td>0.083087</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>16</td>\n",
       "      <td>0.157462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>fw_47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>min_nl_between_24_48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>fw_87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>median_nl_between_24_48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>fw_128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature      rate  rank  rate Random Forest Regressor  \\\n",
       "0         timelength_post_BT  0.177859     0                      0.345726   \n",
       "1          std_nc_diff_24_48  0.096395     1                      0.039033   \n",
       "2            nc_24_before_BT  0.084905     2                      0.159542   \n",
       "3        std_nc_24_before_BT  0.083842     3                      0.044640   \n",
       "4     median_nc_24_before_BT  0.083087     4                      0.008712   \n",
       "..                       ...       ...   ...                           ...   \n",
       "275                    fw_47  0.000000   275                      0.000000   \n",
       "276     min_nl_between_24_48  0.000000   276                      0.000000   \n",
       "277                    fw_87  0.000000   277                      0.000000   \n",
       "278  median_nl_between_24_48  0.000000   278                      0.000000   \n",
       "279                   fw_128  0.000000   279                      0.000000   \n",
       "\n",
       "     rank Random Forest Regressor  rate XGBoost L1 y L2  rank XGBoost L1 y L2  \n",
       "0                               0              0.009992                    11  \n",
       "1                               7              0.153757                     1  \n",
       "2                               1              0.010268                     9  \n",
       "3                               6              0.123043                     2  \n",
       "4                              16              0.157462                     0  \n",
       "..                            ...                   ...                   ...  \n",
       "275                           258              0.000000                   249  \n",
       "276                           198              0.000000                   252  \n",
       "277                           239              0.000000                   235  \n",
       "278                           200              0.000000                   271  \n",
       "279                           100              0.000000                   262  \n",
       "\n",
       "[280 rows x 7 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_feature_importance(rm_models, data_columns) :\n",
    "\n",
    "    result = get_feature_importance(rm_models, data_columns)\n",
    "\n",
    "    for rm in rm_models :\n",
    "        temp = get_feature_importance([rm], data_columns)\n",
    "        result = result.merge(right=temp[['feature', 'rate', 'rank']], on='feature', how='inner', suffixes=(None, ' ' + rm.name) )\n",
    "    \n",
    "    return result\n",
    "\n",
    "show_feature_importance(rm_models=rm_models, data_columns=X_train.columns)\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
